{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b32730af",
   "metadata": {},
   "source": [
    "# Model v1 - dropping features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac2b317",
   "metadata": {},
   "source": [
    "We have been keeping track of features to drop so far:\n",
    "- based on the p-value of the coefficient from the OLS baseline model and\n",
    "- the test for multicollinearity that was performed\n",
    "\n",
    "We need to add to that list the date and price to ensure that all necessary columns are dropped for our next model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c57e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop.extend(['date','price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb87450",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(features_to_drop, axis=1)\n",
    "y = df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47d91b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                   random_state=0)\n",
    "\n",
    "model_v1 = LinearRegression()\n",
    "model_v1.fit(X_train,y_train)\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "baseline_scores = cross_validate(estimator=model_v1, X=X_train,\n",
    "                                 y=y_train, return_train_score=True, \n",
    "                                 cv=splitter)\n",
    "\n",
    "print('------------------------------------')\n",
    "print('Cross Validation Scores on X_train')\n",
    "print('Train score:', baseline_scores['train_score'].mean())\n",
    "print('Test score:', baseline_scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186f2c17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "model_v1_results = sm.OLS(y_train, X_train).fit()\n",
    "model_v1_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250e412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v1_df = pd.DataFrame(model_v1_results.pvalues.sort_values(ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecff10b",
   "metadata": {},
   "source": [
    "Now we can pull out all features whose coefficients' p-value was greater than the threshold (0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c42cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pvalues = model_v1_df[model_v1_df[0] > 0.05]\n",
    "high_pvalues.reset_index(inplace=True)\n",
    "high_pvalues.columns = ['feature', 'p_value']\n",
    "high_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2babf690",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = X.corr().abs().stack().reset_index().sort_values(0,ascending=False)\n",
    "test_df['pairs'] = list(zip(test_df.level_0, test_df.level_1))\n",
    "test_df.set_index(['pairs'], inplace=True)\n",
    "test_df.drop(['level_0', 'level_1'], axis=1, inplace=True)\n",
    "test_df.columns = ['mc']\n",
    "test_df[(test_df.mc > 0.75) & (test_df.mc < 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop.extend(list(high_pvalues.feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33361c9",
   "metadata": {},
   "source": [
    "## Model v2 - 2nd round dropping features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0aa5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(features_to_drop, axis=1)\n",
    "y = df.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeef1b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                   random_state=0)\n",
    "\n",
    "model_v2 = LinearRegression()\n",
    "model_v2.fit(X_train,y_train)\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "baseline_scores = cross_validate(estimator=model_v2, X=X_train,\n",
    "                                 y=y_train, return_train_score=True, \n",
    "                                 cv=splitter)\n",
    "\n",
    "print('------------------------------------')\n",
    "print('Cross Validation Scores on X_train')\n",
    "print('Train score:', baseline_scores['train_score'].mean())\n",
    "print('Test score:', baseline_scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018e377",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train = sm.add_constant(X_train)\n",
    "model_v2_results = sm.OLS(y_train, X_train).fit()\n",
    "model_v2_results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a297bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_v2_df = pd.DataFrame(model_v2_results.pvalues.sort_values(ascending=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f77627",
   "metadata": {},
   "source": [
    "Now we can pull out all features whose coefficients' p-value was greater than the threshold (0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b25a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_pvalues = model_v2_df[model_v2_df[0] > 0.05]\n",
    "high_pvalues.reset_index(inplace=True)\n",
    "high_pvalues.columns = ['feature', 'p_value']\n",
    "high_pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c938a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_df = X.corr().abs().stack().reset_index().sort_values(0,ascending=False)\n",
    "test_df['pairs'] = list(zip(test_df.level_0, test_df.level_1))\n",
    "test_df.set_index(['pairs'], inplace=True)\n",
    "test_df.drop(['level_0', 'level_1'], axis=1, inplace=True)\n",
    "test_df.columns = ['mc']\n",
    "test_df[(test_df.mc > 0.75) & (test_df.mc < 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcf3039",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop.extend(['zip_98006'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2a4e1",
   "metadata": {},
   "source": [
    "# Removing outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014df9e1",
   "metadata": {},
   "source": [
    "## by 'sqft_living'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb9c0c6",
   "metadata": {},
   "source": [
    "During EDA we saw through boxplotting that there are lots of outliers in this feature. We will identify and remove those homes from the dataset and see if our model becomes more accurate at predicting price for a normal home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0c4f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8167e6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy.sqft_living.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbf2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_limit = df_copy.sqft_living.mean() + 3*df_copy.sqft_living.std()\n",
    "upper_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab271f9",
   "metadata": {},
   "source": [
    "If we define outlier as any value more than 3x the standard deviation over the average, then we should drop all homes with a square footage over 4,834"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2222f5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df_copy[df_copy.sqft_living <= upper_limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af1c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copy.drop(features_to_drop, axis=1)\n",
    "y = df_copy.price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                   random_state=0)\n",
    "\n",
    "model_v3 = LinearRegression()\n",
    "model_v3.fit(X_train,y_train)\n",
    "\n",
    "splitter = ShuffleSplit(n_splits=5, test_size=0.2, random_state=0)\n",
    "\n",
    "baseline_scores = cross_validate(estimator=model_v3, X=X_train,\n",
    "                                 y=y_train, return_train_score=True, \n",
    "                                 cv=splitter)\n",
    "\n",
    "print('------------------------------------')\n",
    "print('Cross Validation Scores on X_train')\n",
    "print('Train score:', baseline_scores['train_score'].mean())\n",
    "print('Test score:', baseline_scores['test_score'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd29968f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f7c315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac14dd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b857da86",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102170c9",
   "metadata": {},
   "source": [
    "Other than 'date' and 'price', these are the features dropped through the first two OLS linear regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e25f1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(features_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c63cbc",
   "metadata": {},
   "source": [
    "## Renovation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05ecfc",
   "metadata": {},
   "source": [
    "Set up new dataframe 'renovation_features' to hold engineered features before joining in with original features.\n",
    "\n",
    "We are first working on the renovation status, so we will need some features: yr_built, yr_renovated, and sale_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec23b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "renovation_features = df[['yr_built', 'yr_renovated', 'sale_year']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4ebed9",
   "metadata": {},
   "source": [
    "During research on renovations, it seems like a general industry standard is that a home is considered renovated if the renovation took place within 15 years. We are engineering a new feature 'is_renovated' as a boolean, with 1 being the home is renovated within 15 years of sale, and 0 being either never renovated or renovations took place more than 15 years before sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85f2129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def renovation_status(df):\n",
    "    if df.yr_renovated == 0.0:\n",
    "        return 0\n",
    "    else:\n",
    "        if (df.sale_year - df.yr_renovated) > 15:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "        \n",
    "renovation_features['is_renovated'] = renovation_features.apply(renovation_status, axis=1)\n",
    "renovation_features.drop(renovation_features.iloc[:, 0:3], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c24572",
   "metadata": {},
   "outputs": [],
   "source": [
    "renovation_features.is_renovated.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eaa2b88",
   "metadata": {},
   "source": [
    "Our renovation feature is now a boolean representing homes that were renovated with 15 years of the sale.\n",
    "\n",
    "> The feature resides in a dataframe 'renovation_features' so that we can concat it into our next iteration of features to be modeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2849ca7",
   "metadata": {},
   "source": [
    "## Basement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd733b5",
   "metadata": {},
   "source": [
    "The sqft_basement poses some interesting questions. I think first we want a column to see if there is a basement or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e236a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_features = df[['sqft_living', 'sqft_basement']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1a92a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22525fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_features['has_basement'] = basement_features.sqft_basement.map(lambda x: 1 if x > 0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab4aca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_basement(df):\n",
    "    if df.has_basement == False:\n",
    "        return 0\n",
    "    else:\n",
    "        return round(((df.sqft_basement / df.sqft_living) * 100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30774bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_features['basement_percent'] = basement_features.apply(percent_basement, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb794e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_features.has_basement.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be661e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_features[basement_features.basement_percent > 0].basement_percent.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96414722",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=basement_features[basement_features.basement_percent > 0], x='basement_percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed8b704",
   "metadata": {},
   "source": [
    "In our dataset, 60% of homes have no basement at all.\n",
    "\n",
    "Of those that have basements, the above histogram shows the binned percent of sqft_living that is made up of sqft_basement.\n",
    "\n",
    "It looks like we have a case for a feature that will show if the percent of the home that is basement is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a697e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_features.drop(basement_features.iloc[:, 0:3], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139fb351",
   "metadata": {},
   "outputs": [],
   "source": [
    "basement_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae89bea",
   "metadata": {},
   "source": [
    "## Zipcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f3ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_features = raw_data[['zipcode']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93f5b79",
   "metadata": {},
   "source": [
    "There at 70 different zipcode values in our dataset. We want to try and create a new feature that takes zipcodes and matches them up with cities in our area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c552f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://zipdatamaps.com/king-wa-county-zipcodes\n",
    "zip_city = pd.read_csv('data\\zip_city.csv')\n",
    "\n",
    "zipcode_features = pd.merge(left=zipcode_features, right=zip_city, on='zipcode', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d271d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zipcode_features[zipcode_features.zipcode == 98005]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e6cc0e",
   "metadata": {},
   "source": [
    "zipcode_features can be merged into the larger dataframe to associate a home with a city instead of just a zipcode.\n",
    "\n",
    "Let's explore this a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc46d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes_by_zip = zipcode_features.groupby('city').count()\n",
    "homes_by_zip.reset_index(inplace=True)\n",
    "homes_by_zip.columns = ['city', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf6c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes_by_zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00489fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "homes_by_zip.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba3a4dd",
   "metadata": {},
   "source": [
    "So instead of 70 different zipcodes for a feature, we can have 24 different city names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761eff04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b15c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a775ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651bab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "345px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
